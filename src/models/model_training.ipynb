{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421ad135",
   "metadata": {},
   "source": [
    "# Treinamento de Modelos\n",
    "\n",
    "Este notebook implementa o ponto 4 do trabalho: separar treino e teste, treinar três modelos variados, ajustar hiperparâmetros e registrar métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae91df",
   "metadata": {},
   "source": [
    "## Estratégia\n",
    "\n",
    "- Uso da divisão `train_test_split`\n",
    "- Três modelos diferentes: Random Forest, Gradient Boosting e HistGradientBoosting\n",
    "- Otimização via `RandomizedSearchCV` e validação cruzada\n",
    "- Armazenamento dos resultados para comparações posteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a37fc34",
   "metadata": {},
   "source": [
    "### Preparação do dataset\n",
    "\n",
    "Lê o CSV consolidado, garante que todas as colunas estejam disponíveis e fornece um ponto de partida narrativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60837d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "DATA_FILE = Path('data/clean/olist_ml_ready.csv')\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "print(f'Dataset pronto com {len(df)} registros.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f528b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    'order_id', 'customer_id',\n",
    "    'order_purchase_timestamp', 'order_approved_at',\n",
    "    'order_delivered_carrier_date', 'order_delivered_customer_date',\n",
    "    'order_estimated_delivery_date'\n",
    "]\n",
    "TARGET = 'delivery_time_days'\n",
    "X = df.drop(columns=drop_cols + [TARGET], errors='ignore')\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f44142",
   "metadata": {},
   "source": [
    "### Seleção de features e alvo\n",
    "\n",
    "Remove identificadores temporais e separa a variável `delivery_time_days` para que o treino use apenas features preditivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "print('Treino:', X_train.shape, 'Teste:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df1fd3",
   "metadata": {},
   "source": [
    "### Divisão treino/teste\n",
    "\n",
    "Usa `train_test_split` com seed fixa para reproduzir resultados enquanto deixa 25% da base para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'RandomForest': (\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        {\n",
    "            'n_estimators': [50, 70],\n",
    "            'max_depth': [10, 15],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    ),\n",
    "    'GradientBoosting': (\n",
    "        GradientBoostingRegressor(random_state=42),\n",
    "        {\n",
    "            'n_estimators': [40, 60],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3, 4]\n",
    "        }\n",
    "    ),\n",
    "    'HistGradientBoosting': (\n",
    "        HistGradientBoostingRegressor(\n",
    "            random_state=42,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1,\n",
    "            n_iter_no_change=10\n",
    "        ),\n",
    "        {\n",
    "            'max_iter': [80, 100],\n",
    "            'learning_rate': [0.05, 0.08],\n",
    "            'max_depth': [10, 12]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "searches = {}\n",
    "for name, (estimator, params) in models.items():\n",
    "    print(f'Executando {name}...')\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator,\n",
    "        params,\n",
    "        n_iter=1,\n",
    "        cv=2,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    searches[name] = search\n",
    "    print(f'  Melhor RMSE CV: {-search.best_score_:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a2055",
   "metadata": {},
   "source": [
    "### Busca e ajuste de hiperparâmetros\n",
    "\n",
    "Experimenta 3 modelos com `RandomizedSearchCV`, definindo um espaço enxuto e early stopping para manter o custo computacional em cheque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for name, search in searches.items():\n",
    "    preds = search.best_estimator_.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    metrics.append({\n",
    "        'modelo': name,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2_score(y_test, preds)\n",
    "    })\n",
    "metrics_df = pd.DataFrame(metrics).sort_values('rmse')\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39c04d",
   "metadata": {},
   "source": [
    "### Métricas registradas\n",
    "\n",
    "Calcula RMSE/MAE/R² no conjunto de teste para comparar os melhores estimadores de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef860f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('src/models/trained')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "for name, search in searches.items():\n",
    "    joblib.dump(search.best_estimator_, output_dir / f'{name}.joblib')\n",
    "metrics_df.to_json(Path('src/models/training_metrics.json'), orient='records', indent=2, force_ascii=False)\n",
    "print('Modelos e métricas salvos em src/models/trained e src/models/training_metrics.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de0401",
   "metadata": {},
   "source": [
    "### Salvando artefatos\n",
    "\n",
    "Persistência dos modelos com `joblib` e das métricas em `training_metrics.json` para uso pelos notebooks de análise."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
